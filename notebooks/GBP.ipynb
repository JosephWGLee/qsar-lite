{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4a56b1-b8f4-4aff-8356-9a08f1c9309e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Pytorch utilities, missing a dependency. No module named 'torch'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module requires PyTorch to be installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jofu2\\anaconda3\\envs\\deepchem-env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "from rdkit import RDLogger\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a74de13-3b24-45b0-aab4-b3daf04e49c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing ESOL Delaney solubility dataset \n",
    "\n",
    "def load_data():\n",
    "\n",
    "    \"\"\"\n",
    "    Converts SMILES strings into molecular fingerprints\n",
    "\n",
    "    Args:\n",
    "        smiles (pd.Series or list): SMILES strings\n",
    "        solubility (pd.Series): Experimental solubility values\n",
    "        \n",
    "    Returns:\n",
    "        X (np.ndarray): Molecular feature matrix\n",
    "        y (pd.series): Corresponding solubility values\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\", splitter=\"random\", reload=False)\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "    \n",
    "    train_df = train_dataset.to_dataframe()\n",
    "    valid_df = valid_dataset.to_dataframe()\n",
    "    test_df = test_dataset.to_dataframe()\n",
    "    \n",
    "    smiles_train, sol_train = train_df[\"ids\"], train_df[\"y\"]\n",
    "    #smiles_test, sol_test = test_df[\"ids\"], test_df[\"y\"]\n",
    "    #smiles_valid, sol_valid = valid_df[\"ids\"], valid_df[\"y\"]\n",
    "\n",
    "    return smiles_train, sol_train #(smiles_valid, sol_valid), (smiles_test, sol_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1da648f-ea0a-444c-bcdd-bdc931d034b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Featurise data\n",
    "\n",
    "def featurise_data(smiles, solubility):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts SMILES strings into molecular fingerprints\n",
    "\n",
    "    Args:\n",
    "        smiles (pd.Series or list): SMILES strings\n",
    "        solubility (pd.Series): Experimental solubility values\n",
    "        \n",
    "    Returns:\n",
    "        X (np.ndarray): Molecular feature matrix\n",
    "        y (pd.series): Corresponding solubility values\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    featurizer = dc.feat.CircularFingerprint(size=2048, radius=4)\n",
    "    \n",
    "    X = featurizer.featurize(smiles)\n",
    "    y = solubility\n",
    "\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8691a157-b298-4605-8d87-f33e07162dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split \n",
    "\n",
    "def splitting(X, y, smiles):\n",
    "\n",
    "    \"\"\"\n",
    "    Splits the molecular feature matrix, corresponding solubility values, and SMILES into train, test and split datasets \n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Molecular feature matrix\n",
    "        y (pd.series): Corresponding solubility values\n",
    "        smiles: SMILES strings from training dataset\n",
    "        \n",
    "    Returns:\n",
    "        X_... (np.ndarray): Molecular feature matrix\n",
    "        y_... (pd.series): Split solubility values \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    seed = 400\n",
    "    random.seed(seed)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, smiles_train, smiles_test = train_test_split(X, y, smiles, test_size=0.2, random_state=seed)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, smiles_train, smiles_test, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f275cfaf-d374-4414-9b41-ddf98a0c4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "def first_training(X_train, y_train, seed):\n",
    "\n",
    "    \"\"\"\n",
    "    Initial training of a Gradient Boosting Regressor model\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Molecular feature matrix\n",
    "        y_train (pd.series): Corresponding solubility values\n",
    "        seed (int): random seed for reproducibility \n",
    "        \n",
    "    Returns:\n",
    "        reg (GradientBoostingRegressor): Initial trained model \n",
    "        score (float): The initial cross-validation score \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    reg = GradientBoostingRegressor(random_state=seed)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    score=(cross_val_score(reg, X_train, y_train, cv=3, n_jobs=-1).mean())\n",
    "    return(f\"Initial Cross-validation score is: {score}\")\n",
    "\n",
    "    return reg, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ccb40a-868a-4fe9-87bf-98e0d34a3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional Optimisation\n",
    "\n",
    "def optional_optimisation(X_train, y_train, seed):\n",
    "\n",
    "    \"\"\"\n",
    "    Splits the molecular feature matrix, corresponding solubility values, and SMILES into train, test and split datasets \n",
    "\n",
    "    Args:\n",
    "        seed (int): Random seed for reproducibility  \n",
    "        X_... (np.ndarray): Molecular feature matrix\n",
    "        y_... (pd.series): Split solubility values \n",
    "        \n",
    "    Returns:\n",
    "        search (RandomizedSearchCV): Fitted randomised search object\n",
    "        best_params (dict): The best parameters from the optimisation parameter grid  \n",
    "        best_optimisation_score (Float): The best cross-validation score\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #Base regressor \n",
    "    reg = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "    #Example optimisation parameters. For exhaustive searches, use a range of values. \n",
    "    optimisation_param_grid = {\n",
    "        \"n_estimators\": [500],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\":[7],\n",
    "        \"min_samples_leaf\": [4],\n",
    "        \"min_samples_split\": [6], \n",
    "        \"subsample\": [0.7]\n",
    "    }\n",
    "    \n",
    "    #Can remove randomised search CV for machines with better GPUS\n",
    "    search = RandomizedSearchCV(reg, param_distributions= optimisation_param_grid, n_iter=100, cv=3, n_jobs=-1, verbose=2, random_state=seed)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "    best_optimisation_score = search.best_score_\n",
    "    \n",
    "    print(f\"Best Training Parametres: {best_params}\")\n",
    "    print(f\"Best Training Score: {best_optimisation_score}\")\n",
    "\n",
    "    return search, best_params, best_optimisation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e672ee49-0142-4e79-97fd-5084a3692200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final training  \n",
    "\n",
    "def final_training(X_train, y_train, best_params, seed):\n",
    "\n",
    "    \"\"\"\n",
    "    Final training  \n",
    "\n",
    "    Args:\n",
    "        seed (int): Random seed for reproducibility  \n",
    "        X_... (np.ndarray): Molecular feature matrix\n",
    "        y_... (pd.series): Split solubility values \n",
    "        best_params (dict): The best parameters from the optimisation parameter grid  \n",
    "        \n",
    "    Returns:\n",
    "        reg (GradientBoostingRegressor): Final trained model \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    reg = GradientBoostingRegressor(\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "        min_samples_split=best_params[\"min_samples_split\"],\n",
    "        subsample=best_params[\"subsample\"],\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Final model trained on full training data\")\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90bfa51-14dd-41d3-81d8-6d05e1961a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes\n",
    "\n",
    "def dataframe_creation(reg, x_test, y_test, smiles_test, X_train, y_train, smiles_train):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates a datarame for the trained and test data \n",
    "\n",
    "    Args:\n",
    "\n",
    "        reg (GradientBoostingRegressor): Final trained model\n",
    "        smiles_train: SMILES strings from training dataset\n",
    "        smiles_test: SMILES strings from test dataset \n",
    "        X_... (np.ndarray): Molecular feature matrix\n",
    "        y_... (pd.series): Split solubility values \n",
    "        \n",
    "    Returns:\n",
    "        test_dataframe (pd.series): Test dataframe values\n",
    "        train_dataframe (pd.series): Train dataframe values \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def build_df(X, y, smiles):\n",
    "        preds = reg.predict(X)\n",
    "        residuals = preds - y \n",
    "        return pd.DataFrame({\"SMILES\":smiles, \n",
    "                             \"Actual Solubility logS [mol/L]\": y,\n",
    "                             \"Predicted Solubility logS [mol/L]\": preds,\n",
    "                             \"Residuals\": residuals\n",
    "                            })\n",
    "\n",
    "    train_dataframe = build_df(X_train, y_train, smiles_train)\n",
    "    test_dataframe = build_df(X_test, y_test, smiles_test)\n",
    "                             \n",
    "    return test_dataframe, train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cdb626-a78b-442d-82f7-167e0d99fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Scores\n",
    "\n",
    "def score_calculation(test_dataframe):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate RMSE and R2 scores for the test_dataframe \n",
    "    \n",
    "    Args:\n",
    "\n",
    "        test_dataframe (pd.DataFrame): Test dataframe values\n",
    "\n",
    "    Returns:\n",
    "        predicted_RMSE (float): Predicted root mean square deviation\n",
    "        predicted_r2_score (float): Predicted r score \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_RMSE = root_mean_squared_error(test_dataframe[\"Actual Solubility logS [mol/L]\"], test_dataframe[\"Predicted Solubility logS [mol/L]\"])\n",
    "    predicted_r2_score = r2_score(test_dataframe[\"Actual Solubility logS [mol/L]\"], test_dataframe[\"Predicted Solubility logS [mol/L]\"])\n",
    "    \n",
    "    print(f\"The predicted RMSE is: {predicted_RMSE}\")\n",
    "    print(f\"The predicted R2 score is: {predicted_r2_score}\")\n",
    "\n",
    "    return predicted_RMSE, predicted_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec153507-a62b-440b-825d-2203a18545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(test_dataframe, predicted_RMSE, predicted_r2_score, save_path=\"scatter_plot.png\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Create a scatter plot for the test data\n",
    "    \n",
    "    Args:\n",
    "\n",
    "        test_dataframe (pd.DataFrame): Test dataframe values\n",
    "        predicted_RMSE (float): Predicted root mean square deviation\n",
    "        predicted_r2_score (float): Predicted r score \n",
    "        save_path (str): File path to scatter plot\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        Nothing \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    min_val = test_dataframe[\"Actual Solubility logS [mol/L]\"].min()\n",
    "    max_val = test_dataframe[\"Actual Solubility logS [mol/L]\"].max()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(test_dataframe[\"Actual Solubility logS [mol/L]\"], test_dataframe[\"Predicted Solubility logS [mol/L]\"], s=3) #x, y\n",
    "    plt.title(\"Predicted molecular solubility vs measured solubility using gradient boosted trees\")\n",
    "    plt.xlabel(\"Measured Solubility logS [mol/L]\")\n",
    "    plt.ylabel(\"Predicted Solubility logS [mol/L]\")\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--')\n",
    "    plt.text(0.9, 0.2, 'R-squared = %.3f\\nRMSE = %.3f' % (predicted_r2_score, predicted_RMSE))\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06667b4-6ce9-4925-8fd2-3bd21932fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual Plot \n",
    "\n",
    "def residual_plot(test_dataframe):\n",
    "\n",
    "    sns.residplot(x=test_dataframe[\"Predicted Solubility logS [mol/L]\"], y=test_dataframe[\"Residuals\"])\n",
    "    plt.title(\"Residual Plot\")\n",
    "    plt.xlabel(\"Predicted Solubility logS [mol/L]\")\n",
    "    plt.ylabel(\"Residuals (Predicted - Actual)\")\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.savefig(\"Residual Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b90079f-9d58-45a1-b71f-2caf3c99cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "\n",
    "def feature_importance(reg, X_train):\n",
    "\n",
    "    importances = reg.feature_importances_ #GB assigns numerical importance to each feature\n",
    "    X_train_df = pd.DataFrame(X_train, columns=[f\"Feature {i}\" for i in range(X_train.shape[1])])\n",
    "    feature_names = X_train_df.columns\n",
    "    \n",
    "    feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.barh(feat_imp_df['Feature'][:20], feat_imp_df['Importance'][:20])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.savefig(\"Feature Importance Plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b05364-ff4e-4390-8ebb-f36abbb1f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the code \n",
    "\n",
    "smiles_train, sol_train = load_data()\n",
    "X, y = featurise_data(smiles_train, sol_train)\n",
    "X_train, X_test, y_train, y_test, smiles_train, smiles_test, seed = splitting(X, y, smiles_train)\n",
    "score, reg = first_training(X_train, y_train, seed)\n",
    "search, reg2, best_params, best_optimisation_score = optional_optimisation(reg, X_train, y_train)\n",
    "reg = final_training(X_train, y_train, best_params, seed=400)\n",
    "test_dataframe, train_dataframe = dataframe_creation(reg, y_test, smiles_test, X_train, y_train, smiles_train)\n",
    "predicted_RMSE, predicted_r2_score = score_calculation(test_dataframe, train_dataframe)\n",
    "scatter_plot(test_dataframe, predicted_RMSE, predicted_r2_score)\n",
    "residual_plot(test_dataframe)\n",
    "feature_importance(reg, X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepchem-env)",
   "language": "python",
   "name": "deepchem-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
