{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4a56b1-b8f4-4aff-8356-9a08f1c9309e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Pytorch utilities, missing a dependency. No module named 'torch'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module requires PyTorch to be installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jofu2\\anaconda3\\envs\\deepchem-env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a74de13-3b24-45b0-aab4-b3daf04e49c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing ESOL Delaney solubility dataset \n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\", splitter=\"random\")\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "    \n",
    "    train_df = train_dataset.to_dataframe()\n",
    "    valid_df = valid_dataset.to_dataframe()\n",
    "    test_df = test_dataset.to_dataframe()\n",
    "    \n",
    "    smiles_train, sol_train = train_df[\"ids\"], train_df[\"y\"]\n",
    "    smiles_test, sol_test = test_df[\"ids\"], test_df[\"y\"]\n",
    "    smiles_valid, sol_valid = valid_df[\"ids\"], valid_df[\"y\"]\n",
    "\n",
    "    return (smiles_train, sol_train), (smiles_valid, sol_valid), (smiles_test, sol_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1da648f-ea0a-444c-bcdd-bdc931d034b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Featurise data\n",
    "\n",
    "def featurise_data(smiles, solubility):\n",
    "    \n",
    "    featurizer = dc.feat.CircularFingerprint(size=2048, radius=4)\n",
    "    \n",
    "    X = featurizer.featurize(smiles)\n",
    "    y = solubility\n",
    "\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8691a157-b298-4605-8d87-f33e07162dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split \n",
    "\n",
    "def splitting(X, y, smiles):\n",
    "\n",
    "    seed = 400\n",
    "    random.seed(seed)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, smiles_train, smiles_test = train_test_split(X, y, smiles, test_size=0.2, random_state=seed)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, smiles_train, smiles_test, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f275cfaf-d374-4414-9b41-ddf98a0c4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "def training(X_train, y_train, seed):\n",
    "\n",
    "    reg = GradientBoostingRegressor(random_state=seed)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    score=(cross_val_score(reg, X_train, y_train, cv=3, n_jobs=-1).mean())\n",
    "    print(f\"Cross-validation score is: {score}\")\n",
    "\n",
    "    return score, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ccb40a-868a-4fe9-87bf-98e0d34a3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional Optimisation\n",
    "\n",
    "def optional_optimisation(reg, X_train, y_train):\n",
    "\n",
    "    #Example optimisation parameters\n",
    "    \n",
    "    optimisation_param_grid = {\n",
    "        \"n_estimators\": [10, 50, 100, 500],\n",
    "        \"learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        \"max_depth\":[3, 5, 7, 9],\n",
    "        \"min_samples_leaf\": [1, 2, 3, 4, 5],\n",
    "        \"min_samples_split\": [2, 4, 6, 8, 10], \n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    reg2 = GridSearchCV(reg, optimisation_param_grid, cv=3, n_jobs=-1)\n",
    "    \n",
    "    search = RandomizedSearchCV(reg, param_distributions= optimisation_param_grid, n_iter=100, cv=3, n_jobs=-1, verbose=2)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = search.best_params_\n",
    "    best_optimisation_score = search.best_score_\n",
    "    \n",
    "    print(f\"Best Training Parametres: {best_params}\")\n",
    "    print(f\"Best Training Score: {best_optimisation_score}\")\n",
    "\n",
    "    return search, reg2, best_params, best_optimisation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05d652-fb18-4339-84d2-90532def627b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730701da-e4a7-4898-a25b-18ebbd8d0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Done this all wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e672ee49-0142-4e79-97fd-5084a3692200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final training  \n",
    "\n",
    "def final_train(reg, X_train, y_train):\n",
    "\n",
    "    test_param_grid = {\n",
    "        \"n_estimators\": [500],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\":[7],\n",
    "        \"min_samples_leaf\": [4],\n",
    "        \"min_samples_split\": [6], \n",
    "        \"subsample\": [0.7]\n",
    "    }\n",
    "    \n",
    "    test_regression = GridSearchCV(reg, test_param_grid, cv=3, n_jobs=-1)\n",
    "    test_regression.fit(X_train, y_train)\n",
    "\n",
    "    best_test_score = test_regression.best_score_\n",
    "    \n",
    "    print(f\"Best Test Score: {best_test_score}\")\n",
    "\n",
    "    return best_test_score, test_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b90bfa51-14dd-41d3-81d8-6d05e1961a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes\n",
    "\n",
    "def dataframe_creation(test_regression, y_test, smiles_test, X_train, y_train, smiles_train):\n",
    "\n",
    "    test_data = {\"Predicted Solubility logS [mol/L]\" : test_regression.predict(X_test), \n",
    "                 \"Actual Solubility logS [mol/L]\" : y_test, \n",
    "                 \"SMILES\" : smiles_test\n",
    "                }\n",
    "    \n",
    "    test_data[\"Residuals\"] = test_data[\"Predicted Solubility logS [mol/L]\"] - test_data[\"Actual Solubility logS [mol/L]\"]\n",
    "    test_dataframe = pd.DataFrame(data=test_data)\n",
    "    \n",
    "    train_data = {\"Predicted Solubility logS [mol/L]\" : reg.predict(X_train), \n",
    "                  \"Actual Solubility logS [mol/L]\" : y_train,\n",
    "                  \"SMILES\" : smiles_train\n",
    "                 }\n",
    "    \n",
    "    train_data[\"Residuals\"] = train_data[\"Predicted Solubility logS [mol/L]\"] - train_data[\"Actual Solubility logS [mol/L]\"]\n",
    "    train_dataframe = pd.DataFrame(data=train_data)\n",
    "\n",
    "    return test_dataframe, train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99cdb626-a78b-442d-82f7-167e0d99fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Scores\n",
    "\n",
    "def score_calculation(test_dataframe, train_dataframe):\n",
    "\n",
    "    predicted_RMSE = root_mean_squared_error(test_dataframe[\"Predicted Solubility logS [mol/L]\"], test_dataframe[\"Actual Solubility logS [mol/L]\"])\n",
    "    predicted_r2_score = r2_score(test_dataframe[\"Predicted Solubility logS [mol/L]\"], test_dataframe[\"Actual Solubility logS [mol/L]\"])\n",
    "    \n",
    "    print(f\"The predicted RMSE is: {predicted_RMSE}\")\n",
    "    print(f\"The predicted R2 score is: {predicted_r2_score}\")\n",
    "\n",
    "    return predicted_RMSE, predicted_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec153507-a62b-440b-825d-2203a18545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter graph \n",
    "\n",
    "def scatter_plot(test_dataframe, predicted_RMSE, predicted_r2_score):\n",
    "\n",
    "    plt.scatter(test_dataframe[\"Predicted Solubility logS [mol/L]\"], test_dataframe[\"Actual Solubility logS [mol/L]\"], s=3) #x, y\n",
    "    plt.title(\"Predicted molecular solubility vs measured solubility using gradient boosted trees\")\n",
    "    plt.xlabel(\"Estimated Solubility logS [mol/L]\")\n",
    "    plt.ylabel(\"Measured Solubility logS [mol/L]\")\n",
    "    plt.text(0.9, 0.2, 'R-squared = %.3f\\nRMSE = %.3f' % (predicted_r2_score, predicted_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d06667b4-6ce9-4925-8fd2-3bd21932fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual Plot \n",
    "\n",
    "def residual_plot(test_dataframe):\n",
    "\n",
    "    sns.residplot(x=test_dataframe[\"Predicted Solubility logS [mol/L]\"], y=test_dataframe[\"Residuals\"])\n",
    "    plt.title(\"Residual Plot\")\n",
    "    plt.xlabel(\"Predicted Solubility logS [mol/L]\")\n",
    "    plt.ylabel(\"Residuals (Predicted - Actual)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b90079f-9d58-45a1-b71f-2caf3c99cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "\n",
    "def feature_importance(test_regression):\n",
    "\n",
    "    best_model = test_regression.best_estimator_ #Get trained model with best hyperparametres \n",
    "    importances = best_model.feature_importances_ #GB assigns numerical importance to each feature\n",
    "    X_train_df = pd.DataFrame(X_train, columns=[f\"Feature {i}\" for i in range(X_train.shape[1])])\n",
    "    feature_names = X_train_df.columns\n",
    "    \n",
    "    feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.barh(feat_imp_df['Feature'][:20], feat_imp_df['Importance'][:20])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepchem-env)",
   "language": "python",
   "name": "deepchem-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
